## Tasking 1 (Week 5; Complete by Friday)

There is a demo (under the webscraper folder) on how to use selenium to web-scrape the Kickstarter platform. Used headless mode in order to avoid Kickstarter's automated browsing detection. (If yall have troubles, can try to do the following below)

Instead of using a fresh Selenium instance (which Kickstarter may detect), load an existing Chrome profile.
1.	Find your Chrome user data path:
```
•	Windows: C:\Users\YourUser\AppData\Local\Google\Chrome\User Data
•	Mac: ~/Library/Application Support/Google/Chrome/
•	Linux: ~/.config/google-chrome/
```
2.	Modify Selenium to use it:

```
options = Options()
options.add_argument("user-data-dir=C:/Users/YourUser/AppData/Local/Google/Chrome/User Data")
options.add_argument("profile-directory=Default")  # Use your Chrome's main profile

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
```

### Taskings 

Try to get the working code out by mid week (tues/wed), so that you can at least run the code every day to get a few days worth of data. 

- Chong Sun & Jeff
    * Scrape the data off Kickstarter (Technology section, Still live, all of them): more specifically, 
        * the comments from the backers under the comments tab 
        * the data from the updates tab

- Alyssa & Shi Ying
    * Scrape the data off Kickstarter (Technology section, Still live, all of them): more specifically
        * the data from the community tab (ie how many people support, how many backers from each city/country, new backers, returning backers)

- All to present on friday: 
    * Look into some models for sentiment analysis and time series analysis and how these 2 can be merged together. 

Note: some of the data requires you to click on buttons within the website before you can pull it. thats why i used selenium 

